{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Dataset Process Part\n",
    "Thanks for reading this notebook. Please refer to the ./PittsburghCensus and ./LLMProcess for more details! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Text Data**<br>\n",
    "For the text data part, we choose to leverage the large language model API to process, reason, understand and finally give us an evaluation for the best neighborhood in Pittsburgh.\n",
    "Specifically, we call [Doubao API](https://team.doubao.com/en/), a llm provide by bytedance. We choose doubao since there are more than 100,000 items in the total dataset, we have to find a model is fast, allowing for high-concurency and cheap. We use doubao to reason and generate a coarse summarization for the Non-Traffic Citations and Monthly Criminal Activity Dashboard to condense the information and summarize them into predefined labels. After we get the summarized item for each crime, we could visualize them with a word cloud. <br>\n",
    "\n",
    "Next, we use [Sonar API](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api) provided by Perplexity, we choose it as our judge to final evaluate because \n",
    " - It is a larger model and is suitable for complex reasoning\n",
    " - Perplexity is famous for online searching, we hope this might reduce the hallucination and help better evaluate the result\n",
    " - Perplexity provide 5 free credit for students!\n",
    "To further reduce the context windows, we use a rank sum to get a coarse ranking for the processed data and we only ask model to choose between the 5 neighbourhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics \n",
    "\n",
    "We use language model to evaluate the result and finally generate the best neighborhood.\n",
    "\n",
    "This is the final ranking provide by Perplexity API:\n",
    "\n",
    "ü•á Final Rank (Based on Composite Lifestyle Fit)\n",
    "üèÜ Regent Square ‚Äî Best overall mix of family-friendliness, culture, nature, and charm. Strong community events. Slightly underrated.\n",
    "\n",
    "Point Breeze ‚Äî Elegant, safe, green. A bit pricier, but excellent for stability and long-term quality of life.\n",
    "\n",
    "Central Northside ‚Äî Strong urban lifestyle and cultural identity. Some residual safety concerns, but improving fast.\n",
    "\n",
    "Greenfield ‚Äî Great affordability and recreation access. A bit weaker in character or ‚Äúdestination‚Äù feel compared to others.\n",
    "\n",
    "Polish Hill ‚Äî Super affordable and edgy-cool. But less green space and weaker infrastructure may limit broader appeal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corase processing with Doubao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMProcess.CallAPI import judge_hood_crime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "citation_df = pd.read_csv(\"PittsburghCensus/summary_all.csv\")\n",
    "ctr_north = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Central North Side\"]\n",
    "pohill    = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Polish Hill\"]\n",
    "rsqure    = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Regent Square\"]\n",
    "gfiled    = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Greenfield\"]\n",
    "pbreeze   = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Point Breeze\"]\n",
    "\n",
    "\n",
    "records_ctr_north = ctr_north[\"SUMMARY\"].to_string()\n",
    "records_pohill    = pohill[\"SUMMARY\"].to_string()\n",
    "records_rsqure    = rsqure[\"SUMMARY\"].to_string()\n",
    "records_gfiled    = gfiled[\"SUMMARY\"].to_string()\n",
    "records_pbreeze   = pbreeze[\"SUMMARY\"].to_string()\n",
    "\n",
    "# print(records_ctr_north)\n",
    "# print(records_pohill)\n",
    "# print(records_rsqure)\n",
    "# print(records_gfiled)\n",
    "# print(records_pbreeze)\n",
    "\n",
    "\n",
    "# print(crime_records)\n",
    "\n",
    "# crime_keywords, hood_name = judge_hood_crime(hood_name=\"Central North Side\", crime_records=crime_records)\n",
    "# print(crime_keywords)\n",
    "# print(hood_name)\n",
    "\n",
    "\n",
    "\n",
    "keywords_list = []\n",
    "neighborhood_list = []\n",
    "\n",
    "keywords_list.append(judge_hood_crime(hood_name=\"Central North Side\", crime_records=records_ctr_north))\n",
    "neighborhood_list.append(\"Central North Side\")\n",
    "\n",
    "keywords_list.append(judge_hood_crime(hood_name=\"Polish Hill\", crime_records=records_pohill))\n",
    "neighborhood_list.append(\"Polish Hill\")\n",
    "\n",
    "keywords_list.append(judge_hood_crime(hood_name=\"Regent Square\", crime_records=records_rsqure))\n",
    "neighborhood_list.append(\"Regent Square\")\n",
    "\n",
    "keywords_list.append(judge_hood_crime(hood_name=\"Greenfield\", crime_records=records_gfiled))\n",
    "neighborhood_list.append(\"Greenfield\")\n",
    "\n",
    "keywords_list.append(judge_hood_crime(hood_name=\"Point Breeze\", crime_records=records_pbreeze))\n",
    "neighborhood_list.append(\"Point Breeze\")\n",
    "\n",
    "\n",
    "for i in range(len(keywords_list)):\n",
    "    print(neighborhood_list[i])\n",
    "    print(keywords_list[i])\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge with Sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMProcess.CallAPI import judge_hood_all\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "rank_df = pd.read_csv(\"PittsburghCensus/rank_sum.csv\")\n",
    "citation_df = pd.read_csv(\"PittsburghCensus/summary_all.csv\")\n",
    "print(rank_df.head(5))\n",
    "\n",
    "# we only process the top 5 neighborhoods\n",
    "#         NEIGHBORHOOD  crime_rank  facility_rank  steps_rank  park_rank  tree_rank  student_rank  rank_sum\n",
    "# 0  CENTRAL NORTHSIDE        61.0           18.0        42.0       54.0       62.0          48.0     285.0\n",
    "# 1        POLISH HILL        42.0           56.0        60.0       55.0       40.0          12.0     265.0\n",
    "# 2      REGENT SQUARE        59.0           59.0        10.0       58.0       58.0          17.0     261.0\n",
    "# 3         GREENFIELD        39.0           27.0        53.0       46.0       39.0          50.0     254.0\n",
    "# 4       POINT BREEZE        55.0           39.0        11.0       59.0       47.0          26.0     237.0\n",
    "\n",
    "\n",
    "score_list = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    hood_name = rank_df.iloc[i][\"NEIGHBORHOOD\"]\n",
    "    crime_score = rank_df.iloc[i][\"crime_rank\"]\n",
    "    facility_score = rank_df.iloc[i][\"facility_rank\"]\n",
    "    steps_score = rank_df.iloc[i][\"steps_rank\"]\n",
    "    park_score = rank_df.iloc[i][\"park_rank\"]\n",
    "    tree_score = rank_df.iloc[i][\"tree_rank\"]\n",
    "    student_score = rank_df.iloc[i][\"student_rank\"]\n",
    "    score_sum = rank_df.iloc[i][\"rank_sum\"]\n",
    "\n",
    "    score_record = f\"\"\"\n",
    "    All the scores are higher the better.\n",
    "    In neighborhood {hood_name},\n",
    "    the crime score is {crime_score},\n",
    "    the facility score is {facility_score},\n",
    "    the steps score is {steps_score},\n",
    "    the park score is {park_score},\n",
    "    the tree score is {tree_score},\n",
    "    the student score is {student_score},\n",
    "    the total score sum up to {score_sum}\n",
    "    \"\"\"\n",
    "    score_list.append(score_record)\n",
    "\n",
    "ctr_north = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Central North Side\"][\"SUMMARY\"].to_string()\n",
    "pohill    = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Polish Hill\"][\"SUMMARY\"].to_string()\n",
    "rsqure    = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Regent Square\"][\"SUMMARY\"].to_string()\n",
    "gfiled    = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Greenfield\"][\"SUMMARY\"].to_string()\n",
    "pbreeze   = citation_df[citation_df[\"NEIGHBORHOOD\"] == \"Point Breeze\"][\"SUMMARY\"].to_string()\n",
    "\n",
    "records = [ctr_north, pohill, rsqure, gfiled, pbreeze]\n",
    "\n",
    "final_result = []\n",
    "\n",
    "for i in range(5):\n",
    "    final_result.append(score_list[i] + \"The detailed crime records are: \" + records[i])\n",
    "    print(final_result[i])\n",
    "\n",
    "result = judge_hood_all(final_result)\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "Our text process part explores the use of large language models (LLMs) to assist in evaluating Pittsburgh neighborhoods based on a mix of qualitative and quantitative crime-related text data. By leveraging the high-concurrency, cost-effective **Doubao API** for initial summarization and the more powerful **Sonar API** from Perplexity for final evaluation, we design a two-stage pipeline that balances scalability and reasoning depth.\n",
    "\n",
    "However, several limitations remain that influence the robustness and reliability of the results, please refer to our slides and presentation for more details:\n",
    "\n",
    "- **Prompt Dependency**: The outcome is highly sensitive to the system prompt design and model choice. Small changes in phrasing or task framing can significantly alter the generated summaries or final evaluations, if we use the deep research model, the model tend to reason from the internet knowledge.\n",
    "  \n",
    "- **Model Hallucination on Hard Tasks**: When the reasoning complexity exceeds the model‚Äôs effective context length or clarity, especially in comparative evaluations with dense crime data, we observed instances of hallucination or overconfident assertions not grounded in input facts.\n",
    "\n",
    "- **Monotonous and Redundant Input**: Much of the raw data (e.g., repetitive criminal activity entries) lacks semantic diversity. This can cause the model to overfit on trivial patterns, skewing interpretation or leading to surface-level summaries. Also, we only use the crime data and rank of other data, which might not be enough to give a comprehensive evaluation.\n",
    "\n",
    "- **Context Window and Truncation**: Despite ranking and filtering steps to reduce context length, LLMs may still miss relevant information or fail to maintain coherence across long-form comparisons. This limits their effectiveness in nuanced tradeoff analysis.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
